<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Interactive Audio Lab | Lab description</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Interactive Audio Lab" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lab description" />
<meta property="og:description" content="Lab description" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Interactive Audio Lab" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Interactive Audio Lab" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Lab description","headline":"Interactive Audio Lab","name":"Interactive Audio Lab","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->
<link href="https://fonts.googleapis.com/css?family=Oswald|Roboto+Condensed" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/main.css""><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Interactive Audio Lab" /></head>
<body>
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a><header>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark primary-nav" aria-label="primary navigation">
    <div class="container">
      <a class="navbar-brand display" href="/">INTERACTIVE AUDIO LAB</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    
      <!-- main navigation -->
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto"> 
            <li class="nav-item">
              
                <a class="nav-link " href="/projects/">
                  Projects
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/publications/">
                  Publications
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/resources/">
                  Resources
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/people/">
                  People
                </a>
              
            </li>
          
    
        </ul>

        <!-- Social media links -->
        <ul class="navbar-nav mr-sm-2">
            <li class="nav-item">
                <a class="nav-link external-link social-link" href="https://github.com/interactiveaudiolab" target="_blank"><span class="fab fa-github" title="Interactive Audio Lab on GitHub"></span><span class="sr-only">Link opens in a new window</span></a>
            </li>
            <li class="nav-item">
                <a class="nav-link external-link social-link" href="https://www.youtube.com/channel/UCY-jggB_-R3rYaTsWN2_Ssw" target="_blank"><span class="fab fa-youtube" title="Interactive Audio Lab on YouTube"></span><span class="sr-only">Link opens in a new window</span></a>
              </li>
        </ul>
      </div>
    </div> <!-- end container -->
  </nav>

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary subnav" aria-label="subnavigation">
  </nav>
</header>

<div class="container">
    <main id="content" class="content" tabindex=-1 aria-label="Content">
        <div class=""><p>Headed by <a href="https://bryan-pardo.github.io">Prof. Bryan Pardo</a>, the Interactive Audio Lab is in the <a href="https://www.mccormick.northwestern.edu/computer-science/">Computer Science Department of Northwestern University</a>. We develop new methods in <strong>Machine Learning</strong>, <strong>Signal Processing</strong> and <strong>Human Computer Interaction</strong> to make new tools for understanding and manipulating sound.</p>

<p>Ongoing research in the lab is applied to audio scene labeling, audio source separation, inclusive interfaces, new audio production tools and machine audition models that learn without supervision. For more see our <a href="/projects">projects</a> page.</p>

</div>

<hr>

  <div class="row">
    <div class="col-md"><h2 class="h1">Latest News</h2>
          <ul class="list-unstyled"><li class="category-list"><h3>
                <a class="" href="/news/2023/10/18/TorchCrepe.html">
                  TorchCrepe pitch tracker passes 2,000,0000 downloads.
                </a>
              </h3>
              <h4 class="text-muted">Oct 18, 2023</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2023/07/01/VampNet.html">
                  Try the VampNet demo: Music Generation via Masked Acoustic Token Modeling.
                </a>
              </h3>
              <h4 class="text-muted">Jul 1, 2023</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2023/06/01/NSF-grant.html">
                  $440K grant from NSF: Engaging Blind and Visually Impaired Youth in Computer Science through Music Programming
                </a>
              </h3>
              <h4 class="text-muted">Jun 1, 2023</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2022/10/01/Sony-grant.html">
                  $100K grant from Sony to fund speech generation
                </a>
              </h3>
              <h4 class="text-muted">Oct 1, 2022</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2022/09/12/NSF-grant.html">
                  $1.8 million Future of Work award from NSF
                </a>
              </h3>
              <h4 class="text-muted">Sep 12, 2022</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2022/01/01/adobe-project-shasta.html">
                  Our tech inside Adobe&#39;s new AI-powered audio editor
                </a>
              </h3>
              <h4 class="text-muted">Jan 1, 2022</h4></li><li class="category-list"><h3>
                <a class="" href="/news/2021/12/01/bose-hearing-aids.html">
                  Bose releases hearing aids using our tech
                </a>
              </h3>
              <h4 class="text-muted">Dec 1, 2021</h4></li></ul></div>

      <div class="col-md">
            <!-- collection, title, and link needs to be passed into this to work -->

 
 
    <h2 class="h1 pt-2 pb-3">Projects</h2>

    <ul class="list-group">
        
            
                <li class="media preview-list">
    
        <div>
            <img class="mr-3" src="/assets/images/projects/audacity-logo.png" alt="Audacity logo">
        </div>
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/audacity.html">Deep Learning Tools for Audacity</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Hugo Flores Garcia,
                    
                
                    
                        Aldo Aguilar,
                    
                
                    
                        Ethan Manilow,
                    
                
                    
                        Dmitry Vedenko and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>We provide a software framework that lets deep learning practitioners easily integrate their own PyTorch models into the open-source Audacity DAW. This lets ML audio researchers put tools in the hands of sound artists without doing DAW-specific development work.</p>

</p>
        
    </div>
</li>

            
        
            
                <li class="media preview-list">
    
        <div>
            <img class="mr-3" src="/assets/images/projects/speech.png" alt="Speech conversation icon">
        </div>
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/controllable-speech-generation.html">Controllable Speech Generation</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Max Morrison and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>Nuances in speech prosody (i.e., the pitch, timing, and loudness of speech) are a vital part of how we communicate. We utilize generative machine learning models to generate prosody with user control over these nuances and generate speech reflecting user-specified prosody.</p>

</p>
        
    </div>
</li>

            
        
            
                <li class="media preview-list">
    
        <div>
            <img class="mr-3" src="/assets/images/projects/vampnet.png" alt="System description">
        </div>
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/music-audio-generation.html">Music Audio Generation</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Hugo Flores Garcia,
                    
                
                    
                        Prem Seetharaman,
                    
                
                    
                        Rithesh Kumar,
                    
                
                    
                        Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>We introduce VampNet, a masked acoustic token modeling approach to music audio generation. VampNet, made in collaboration with <a href="https://www.descript.com/">Descript</a>, lets us sample coherent music from the model by applying a variety of masking approaches (called prompts) during inference.  Prompting VampNet appropriately, enables music compression, inpainting, outpainting, continuation, and looping with variation (vamping). This makes VampNet a powerful music co-creation tool.</p>

</p>
        
    </div>
</li>

            
        
    </ul>
    
    <h5 class= "h3 pt-3 mb-3"><a href="/projects">Full List of Projects <span class="fas fa-caret-right" aria-hidden="true"></span></a></h5>

          
    </div>
</div>

    </main>
  </div>
  <br></br><footer class="footer bg-light" role="contentinfo">

    <div class="container">

      <div class="row align-items-center footer-copy">
            &copy; 2023 Interactive Audio Lab
            <a class="external-link social-link" href="https://github.com/interactiveaudiolab" target="_blank"><span class="fab fa-github" title="Interactive Audio Lab on GitHub"></span><span class="sr-only">Link opens in a new window</span></a>
            <a class="external-link social-link" href="https://www.youtube.com/channel/UCY-jggB_-R3rYaTsWN2_Ssw" target="_blank"><span class="fab fa-youtube" title="Interactive Audio Lab on YouTube"></span><span class="sr-only">Link opens in a new window</span></a>
    </div>

</footer>

<!-- js scripts for bootstrap and fontawesome -->
<script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js" integrity="sha384-SlE991lGASHoBfWbelyBPLsUlwY1GwNDJo3jSJO04KZ33K2bwfV9YBauFfnzvynJ" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script></body>

</html>
