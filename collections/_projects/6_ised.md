---
name: ISED
creators: [Bongjun Kim and Bryan Pardo]
external-url: http://54.68.168.116/
external-url-text: Web demo
image: /assets/images/projects/ised.png
altdescription: ISED logo
funding: Funding provided by the National Science Foundation
collection: projects
#put full content below the dashed line. full markdown is supported.
---

Interactive Sound Event Detector (I-SED) is a human-in-the-loop interface for sound event annotation that helps users label sound events of interest within a lenghty recording quickly. The annotation is performed by a collaboration between a user and a machine.

The system lets reduce the time required to search for a set of sound events of interest in an audio recording when there are too few labeled examples (e.g., one) of the sound class to train a state-of-the-art machine audio labeling system.

### Demo video
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ss2eGSW4_4w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


### Related papers

[[pdf]](https://interactiveaudiolab.github.io/assets/papers/kim_pardo_tiis_2018.pdf) Bongjun Kim and Bryan Pardo, "A Human-in-the-loop System for Sound Event Detection and Annotation," ACM Transaction on Interactive Intelligent System (TiiS), Vol. 8, Issue 2, Article 13, July 2018.

[[pdf]](https://interactiveaudiolab.github.io/assets/papers/Kim_Pardo_IUI2017.pdf) Bongjun Kim and Bryan Pardo, "I-SED: an Interactive Sound Event Detector," ACM International Conference on Intelligent User Interface (IUI), Limassol, Cyprus, Mar. 2017