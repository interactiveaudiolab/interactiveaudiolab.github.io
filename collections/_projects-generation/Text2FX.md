---
name: Text2FX - Harnessing CLAP Embeddings for Text-Guided Audio Effects
creators: [Annie Chu, Patrick O'Reilly, Julia Barnett, Bryan Pardo]
image: /assets/images/projects/text2fx.png
altdescription: System description
funding: This work supported by NSF Award Number 2222369
collection: projects

#put full content below the dashed line. full markdown is supported.
---
Text2FX leverages CLAP embeddings and differentiable digital signal processing to control audio effects, such as equalization and reverberation, using open-vocabulary natural language prompts (e.g., "make this sound in-your-face and bold"). 

Text2FX operates without retraining any models, relying instead on single-instance optimization within the existing embedding space, thus enabling a flexible, scalable approach to open-vocabulary sound transformations through interpretable and disentangled FX manipulation. While we demonstrate with CLAP, this approach is applicable to any shared text-audio embedding space. Similarly, while we demonstrate with equalization and reverberation, any differentiable audio effect may be controlled. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/nq0HeJ0cwA8?si=g2wgDAWhUYkt7iOS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### [Audio](https://anniejchu.github.io/text2fx/)  [GitHub](https://github.com/anniejchu/text2fx) 

### Related publications
[pdf](/assets/papers/chu2025icassp.pdf) A. Chu, P. O’Reilly, J. Barnett, and B. Pardo, “Text2FX: Harnessing CLAP Embeddings for Text-Guided Audio Effects,” in IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2025.


