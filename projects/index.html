<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Projects | Interactive Audio Lab</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Projects" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lab description" />
<meta property="og:description" content="Lab description" />
<link rel="canonical" href="http://localhost:4000/projects/" />
<meta property="og:url" content="http://localhost:4000/projects/" />
<meta property="og:site_name" content="Interactive Audio Lab" />
<script type="application/ld+json">
{"url":"http://localhost:4000/projects/","headline":"Projects","description":"Lab description","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link href="https://fonts.googleapis.com/css?family=Oswald|Roboto+Condensed" rel="stylesheet">
  <link rel="stylesheet" href="/assets/css/main.css""><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Interactive Audio Lab" /></head>
<body>
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a><header>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark primary-nav" aria-label="primary navigation">
    <div class="container">
      <a class="navbar-brand display" href="/">INTERACTIVE AUDIO LAB</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    
      <!-- main navigation -->
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto"> 
            <li class="nav-item">
              
                <a class="nav-link active" href="/projects/">
                  Projects
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/publications/">
                  Publications
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/resources/">
                  Resources
                </a>
              
            </li>
           
            <li class="nav-item">
              
                <a class="nav-link " href="/people/">
                  People
                </a>
              
            </li>
          
    
        </ul>

        <!-- Social media links -->
        <ul class="navbar-nav mr-sm-2">
            <li class="nav-item">
                <a class="nav-link external-link social-link" href="https://github.com/interactiveaudiolab" target="_blank"><span class="fab fa-github" title="Interactive Audio Lab on GitHub"></span><span class="sr-only">Link opens in a new window</span></a>
            </li>
            <li class="nav-item">
                <a class="nav-link external-link social-link" href="https://www.youtube.com/channel/UCY-jggB_-R3rYaTsWN2_Ssw" target="_blank"><span class="fab fa-youtube" title="Interactive Audio Lab on YouTube"></span><span class="sr-only">Link opens in a new window</span></a>
              </li>
        </ul>
      </div>
    </div> <!-- end container -->
  </nav>

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary subnav" aria-label="subnavigation">
  </nav>
</header>

<div class="container">
    <main id="content" class="content" tabindex=-1 aria-label="Content">
        <header>
        <h1 class="display-5">Projects</h1>
</header>

<hr><div class="">
    <ul class="list-unstyled">
        
            <li class="media preview-list">
    
        <img class="mr-3" src="/assets/images/projects/hands-over-eyes-150by150-shutterstock_354081641.png" alt="Man with hands over his eyes">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/1-eyes-free-interfaces.html">Eyes Free Audio Production</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>This project focuses on building novel accessible tools for creating audio-based content like music or podcasts. The tools should support the needs of blind creators, whether working independently or on teams with sighted collaborators.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="https://via.placeholder.com/150" alt="Placeholder image">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/2-sample-audio-imputation.html">Audio Imputation</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Jinyu Han,
                    
                
                    
                        Gautham J. Mysore,
                    
                
                    
                        Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>Audio imputation is the process of re-synthesizing the missing parts of an audio signal so that after the reconstruction the information inside missing parts is seamlessly recovered.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="https://via.placeholder.com/150" alt="Placeholder image">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/3-sample-tunebot.html">Tunebot</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Bryan Pardo,
                    
                
                    
                        Mark Cartwright,
                    
                
                    
                        Jinyu Han,
                    
                
                    
                        David Little,
                    
                
                    
                        Arefin Huq
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>Tunebot is a search engine that lets you find the music youâ€™re looking for by singing a bit of it (or entering music notation). In response to your query it returns a ranked list of songs you can play. These songs are linked to www.amazon.com, where you can purchase the desired music.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="/assets/images/projects/voogle.png" alt="Voogle logo">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/4-voogle.html">Voogle</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Max Morrison,
                    
                
                    
                        Madhav Ghei,
                    
                
                    
                        and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>Voogle is an audio search engine that lets users search a database of sounds by vocally imitating or providing an example of the sound they are searching for.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="/assets/images/projects/mcft.png" alt="MCFT filter">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/5-mcft.html">Multi-resolution Common Fate Transform</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Fatemeh Pishdadian and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>The <a href="/assets/papers/pishdadian_pardo_mcft_journal_2018.pdf">Multi-resolution Common Fate Transform (MCFT)</a> is an audio signal representation developed in the context of audio source separation.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="/assets/images/projects/ised.png" alt="ISED logo">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/6-ised.html">ISED</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Bongjun Kim and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>Interactive Sound Event Detector (I-SED) is a human-in-the-loop interface for sound event annotation that helps users label sound events of interest within a lenghty recording quickly. The annotation is performed by a collaboration between a user and a machine.</p>

</p>
        
    </div>
</li>
        
            <li class="media preview-list">
    
        <img class="mr-3" src="/assets/images/projects/bootstrapping.png" alt="System diagram of bootstrapping computer audition">
    

    <div class="mt-0 mb-1">
        <h2 class=""><a href="/project/7-bootstrapping.html">Bootstrapping deep learning models for computer audition</a></h2>
        <h3 class=" h4 text-muted">
            <!-- checks for course-number to display course-only information -->
            

            <!-- checks for creators -->
            
                
                    
                        Prem Seetharaman and Bryan Pardo
                    
                
            

        </h3>
        <!-- checking for creators because courses should not list an excerpt -->
        
            <p><p>The human auditory system is remarkable, easily parsing the complex mixtures of speech, music, and environmental sounds that we encounter every day. To appreciate the complexity of the task set before our ears, consider this thought experiment: imagine a crowded lake during summer. Boats are traveling across it in different directions and people are swimming and splashing around. All of this activity manifests as waves rippling across the surface of the lake. Two small channels of water extend out from the lake. The activity on the lake causes waves that reach the channels, causing them to swell and recede. Your task is to describe the activity taking place on the lake, such as how many boats there are, their direction of travel, what kind of boats, how many people there are, how far the boats are, etc. The catch is that you can only observe the two small channels extending from the lake. This seems impossible. Yet, the human auditory system deals with precisely this task all the time and does it with astounding efficacy. The lake of activity (the sounds around us) causes waves (sound pressure waves in air) that reach the two channels (our ears). We process these waves in real-time into an understanding of the auditory world around us.</p>

</p>
        
    </div>
</li>
        
    </ul>
</div>
    </main>
  </div>
  <br></br><footer class="footer bg-light" role="contentinfo">

    <div class="container">

      <div class="row align-items-center footer-copy">
            &copy; 2019 Interactive Audio Lab
            <a class="external-link social-link" href="https://github.com/interactiveaudiolab" target="_blank"><span class="fab fa-github" title="Interactive Audio Lab on GitHub"></span><span class="sr-only">Link opens in a new window</span></a>
            <a class="external-link social-link" href="https://www.youtube.com/channel/UCY-jggB_-R3rYaTsWN2_Ssw" target="_blank"><span class="fab fa-youtube" title="Interactive Audio Lab on YouTube"></span><span class="sr-only">Link opens in a new window</span></a>
    </div>

</footer>

<!-- js scripts for bootstrap and fontawesome -->
<script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js" integrity="sha384-SlE991lGASHoBfWbelyBPLsUlwY1GwNDJo3jSJO04KZ33K2bwfV9YBauFfnzvynJ" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script></body>

</html>
